experiment:
  description: tea-cgan on celeba
  output_loc: /data/namrata/models/tea-cgan/

data:
  datadir: /data/namrata/celebA/img_align_celeba
  captions: data/celeba/captions.txt
  word_vectors: data/celeba/celeba.vec
  batch_size: 64
  num_workers: 8

model:
  modes:
    - train

  epochs: 600
  optimizer:
    generator:
      Adam:
        lr: 0.0002

  network:
    image_encoder:
      - Conv2d:
          in_channels: 3
          out_channels: 32
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - Conv2d:
          in_channels: 32
          out_channels: 32
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 32
      - Conv2d:
          in_channels: 32
          out_channels: 64
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 64
      - Conv2d:
          in_channels: 64
          out_channels: 64
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 64
      - Conv2d:
          in_channels: 64
          out_channels: 256
          kernel_size: 4
          stride: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 256
      - Conv2d:
          in_channels: 256
          out_channels: 512
          kernel_size: 1

    text_encoder:
      - LSTM:
          input_size: 100
          hidden_size: 128
          num_layers: 1
          batch_first: True
          bidirectional: True

    projection_layer:
      - Linear:
          in_features: 256
          out_features: 25
          bias: False

    res_block1:
      - Conv2d:
          in_channels: 1024
          out_channels: 1024
          kernel_size: 3
          stride: 1
          padding: 1
      - BatchNorm2d:
          num_features: 1024
        activation: ReLU
      - Conv2d:
          in_channels: 1024
          out_channels: 1024
          kernel_size: 3
          stride: 1
          padding: 1
      - BatchNorm2d:
          num_features: 1024

    res_block2:
      - Conv2d:
          in_channels: 1024
          out_channels: 1024
          kernel_size: 3
          stride: 1
          padding: 1
      - BatchNorm2d:
          num_features: 1024
        activation: ReLU
      - Conv2d:
          in_channels: 1024
          out_channels: 1024
          kernel_size: 3
          stride: 1
          padding: 1
      - BatchNorm2d:
          num_features: 1024

    image_decoder:
      - Conv2d:
          in_channels: 1024
          out_channels: 256
          kernel_size: 1
        activation: LeakyReLU
      - ConvTranspose2d:
          in_channels: 256
          out_channels: 64
          kernel_size: 4
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 64
      - ConvTranspose2d:
          in_channels: 64
          out_channels: 64
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 64
      - ConvTranspose2d:
          in_channels: 64
          out_channels: 32
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 32
      - ConvTranspose2d:
          in_channels: 32
          out_channels: 32
          kernel_size: 4
          stride: 2
          padding: 1
        activation: LeakyReLU
      - BatchNorm2d:
          - num_features: 32
      - ConvTranspose2d:
          in_channels: 32
          out_channels: 3
          kernel_size: 4
          stride: 2
          padding: 1
        activation: Tanh
